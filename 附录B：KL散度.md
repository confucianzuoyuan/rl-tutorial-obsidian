
KL散度（Kullback-Leibler Divergence, KLD）非常重要。

假设有一个连续型随机变量 $x$ ，其概率密度表示为 $p(x)$ 。此时，函数 $f(x)$ 的期望值可以用下面的数学式表示。

$$
\mathbb{E}_{p(x)}[f(x)]=\int f(x)p(x)dx
$$
关于概率分布 $q(x)$ 的期望值可以用下面的数学式表示。

$$
\mathbb{E}_{q(x)}[f(x)]=\int f(x)q(x)dx
$$

## KL散度的定义

衡量两个概率分布之间差异的一种方法是KL散度。当给定两个概率分布 $p(x)$ 和 $q(x)$ 时，KL散度可以用下面的数学式表示。

$$
D_{KL}(p\Vert q)=\int p(x)\log\frac{p(x)}{q(x)}dx
$$

上面的式子是当 $x$ 为连续型随机变量时的KL散度。当 $x$ 为离散型随机变量时，数学式如下所示。

$$
D_{KL}(p\Vert q)=\sum_x p(x)\log\frac{p(x)}{q(x)}
$$

KL散度具有以下特性：

- 两个概率分布的差异越大，KL散度的值就越大
-  KL散度的值大于或等于0，且仅当两个概率分布相同时，其值才为0
-  KL散度是非对称的衡量指标，因此 $D_{KL}(p\Vert q)$ 和 $D_{KL}(q\Vert p)$ 的值不同

这些特性使得KL散度可以用来衡量两个概率分布的差异程度。下面我们通过具体的例子来了解这些特性。这里以抛硬币为例进行说明。假设一枚硬币正面朝上和反面朝上的概率是确定的，如下所示。

