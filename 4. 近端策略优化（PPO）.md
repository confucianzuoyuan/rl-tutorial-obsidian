
```ad-note
è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼ŒPPOï¼‰ï¼Œå…¶æ€§èƒ½ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ï¼ŒåŒæ—¶ä»£ç å®ç°å’Œä¼˜åŒ–èµ·æ¥æ›´ç®€å•ã€‚
```

å®é™…ä¸Šï¼Œä¸å…¶å®é™…å½±å“ç›¸æ¯”ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸è°¦è™šçš„è¯´æ³•ã€‚ç­–ç•¥æ¢¯åº¦æ–¹æ³•å­˜åœ¨æ”¶æ•›é—®é¢˜ï¼Œè‡ªç„¶ç­–ç•¥æ¢¯åº¦å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œè‡ªç„¶ç­–ç•¥æ¢¯åº¦æ¶‰åŠäºŒé˜¶å¯¼æ•°çŸ©é˜µï¼Œè¿™ä½¿å¾—å®ƒä¸é€‚ç”¨äºå¤§è§„æ¨¡é—®é¢˜ã€‚å¯¹äºå®é™…ä»»åŠ¡æ¥è¯´ï¼Œè®¡ç®—å¤æ‚åº¦å¤ªé«˜ã€‚äººä»¬è¿›è¡Œäº†æ·±å…¥çš„ç ”ç©¶ï¼Œé€šè¿‡è¿‘ä¼¼äºŒé˜¶æ–¹æ³•æ¥é™ä½å¤æ‚åº¦ã€‚PPO é‡‡ç”¨äº†ç•¥æœ‰ä¸åŒçš„æ–¹æ³•ã€‚å®ƒæ²¡æœ‰æ–½åŠ ç¡¬çº¦æŸï¼Œè€Œæ˜¯å°†çº¦æŸå½¢å¼åŒ–ä¸ºç›®æ ‡å‡½æ•°ä¸­çš„æƒ©ç½šã€‚é€šè¿‡ä¸æƒœä¸€åˆ‡ä»£ä»·é¿å…çº¦æŸï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åƒæ¢¯åº¦ä¸‹é™æ³•è¿™æ ·çš„ä¸€é˜¶ä¼˜åŒ–å™¨æ¥ä¼˜åŒ–ç›®æ ‡ã€‚å³ä½¿æˆ‘ä»¬å¶å°”è¿åçº¦æŸï¼ŒæŸå®³ä¹Ÿè¦å°å¾—å¤šï¼Œè®¡ç®—ä¹Ÿç®€å•å¾—å¤šã€‚åœ¨è¯¦ç»†è§£é‡Š PPO ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å¿«é€Ÿè¿‡ä¸€éåŸºæœ¬æ¦‚å¿µã€‚

## æœ€å°åŒ–-æœ€å¤§åŒ– MM ç®—æ³•

æˆ‘ä»¬å¦‚ä½•ä¼˜åŒ–ç­–ç•¥ä»¥æœ€å¤§åŒ–å›æŠ¥ï¼Ÿ

ä½¿ç”¨ Minorize-MaximizationÂ **MM**Â ç®—æ³•ï¼Œé€šè¿‡æœ€å¤§åŒ–ä¸‹é™å‡½æ•°Â $M$Â ï¼ˆä¸‹å›¾è“çº¿ï¼‰æ¥ **è¿­ä»£** å®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥å‡½æ•°åœ¨å±€éƒ¨è¿‘ä¼¼é¢„æœŸå¥–åŠ±Â $Î·$Â ã€‚

![[3.6.excalidraw|600x100]]

é¦–å…ˆï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªåˆå§‹ç­–ç•¥çŒœæµ‹å¼€å§‹ï¼Œå¹¶æ‰¾åˆ°è¯¥ç­–ç•¥ä¸‹Â $Î·$Â çš„ä¸‹ç•ŒÂ $M$ ã€‚æˆ‘ä»¬ä¼˜åŒ– $M$ï¼Œå¹¶å°†Â $M$Â çš„æœ€ä¼˜ç­–ç•¥ä½œä¸ºä¸‹ä¸€ä¸ªçŒœæµ‹ã€‚æˆ‘ä»¬å†æ¬¡åœ¨æ–°çš„çŒœæµ‹ä¸‹é€¼è¿‘æ–°çš„ä¸‹ç•Œï¼Œå¹¶é‡å¤è¿­ä»£ï¼Œç›´åˆ°ç­–ç•¥æ”¶æ•›ã€‚ä¸ºäº†ä½¿å…¶æœ‰æ•ˆï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªæ›´å®¹æ˜“ä¼˜åŒ–çš„ä¸‹ç•ŒÂ $M$ ã€‚

## çº¿æ€§æœç´¢

ä¸»è¦çš„ä¼˜åŒ–æ–¹æ³•æœ‰ä¸¤ç§ï¼šç±»ä¼¼äºæ¢¯åº¦ä¸‹é™çš„çº¿æ€§æœç´¢å’Œç½®ä¿¡åŸŸã€‚æ¢¯åº¦ä¸‹é™åœ¨ä¼˜åŒ–ç›®æ ‡å‡½æ•°æ–¹é¢ç®€å•æ˜“è¡Œã€å¿«é€Ÿä¸”å‡†ç¡®ã€‚è¿™ä¹Ÿæ˜¯å®ƒåœ¨æ·±åº¦å­¦ä¹ ä¸­å¦‚æ­¤å—æ¬¢è¿çš„åŸå› ï¼Œç”šè‡³æœ‰æ›´ç²¾ç¡®çš„æ–¹æ³•å¯ä¾›é€‰æ‹©ã€‚

çº¿æ€§æœç´¢é¦–å…ˆé€‰æ‹©æœ€é™¡å³­çš„æ–¹å‘ï¼Œç„¶åå‘å‰ç§»åŠ¨ä¸€ä¸ªæ­¥é•¿ã€‚ä½†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œè¿™ç§ç­–ç•¥æ€ä¹ˆä¼šå‡ºé”™å‘¢ï¼Ÿè®©æˆ‘ä»¬å¸¦ä¸€ä¸ªæœºå™¨äººå»å¤©ä½¿é™ä¸´å³°å¾’æ­¥æ—…è¡Œã€‚å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬å…ˆç¡®å®šæ–¹å‘ï¼Œç„¶åçˆ¬å±±ã€‚å¦‚æœæ­¥é•¿å¤ªå°ï¼Œåˆ°è¾¾å±±é¡¶å°†éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚ä½†å¦‚æœæ­¥é•¿å¤ªå¤§ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæ‰ä¸‹æ‚¬å´–ã€‚å³ä½¿æœºå™¨äººåœ¨å è½ä¸­å¹¸å­˜ä¸‹æ¥ï¼Œå®ƒè½åœ¨çš„é«˜åº¦ä¹Ÿä¼šæ¯”æˆ‘ä»¬ä¹‹å‰çš„ä½ç½®ä½å¾—å¤šã€‚ç­–ç•¥æ¢¯åº¦ä¸»è¦æ˜¯ä¸€ç§ **åŒç­–ç•¥æ–¹æ³•** ã€‚å®ƒä»å½“å‰çŠ¶æ€æœç´¢åŠ¨ä½œã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç”¨å±€éƒ¨ç³Ÿç³•çš„ç­–ç•¥ä»ç³Ÿç³•çš„çŠ¶æ€é‡æ–°å¼€å§‹æ¢ç´¢ã€‚è¿™ä¼šä¸¥é‡æŸå®³æ€§èƒ½ã€‚

![[1_k9NFvgjf2XGiLiiarp0Q2Q.webp]]

## ç½®ä¿¡åŸŸ

åœ¨ç½®ä¿¡åŸŸä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šæƒ³è¦æ¢ç´¢çš„æœ€å¤§æ­¥é•¿ï¼ˆä¸‹å›¾é»„è‰²åœ†åœˆï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨ç½®ä¿¡åŸŸå†…æ‰¾åˆ°æœ€ä¼˜ç‚¹ï¼Œå¹¶ä»é‚£é‡Œç»§ç»­æœç´¢ã€‚

![[1_eQDsFaMkSXw0g6gVIErXaQ.webp]]

**ç½®ä¿¡åŸŸçš„æœ€å¤§æ­¥é•¿æ˜¯å¤šå°‘ï¼Ÿ**Â åœ¨ç½®ä¿¡åŸŸæ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªåˆå§‹çŒœæµ‹å¼€å§‹ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥åŠ¨æ€åœ°é‡æ–°è°ƒæ•´åŒºåŸŸå¤§å°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ–°ç­–ç•¥å’Œå½“å‰ç­–ç•¥çš„å·®å¼‚å˜å¤§ï¼ˆåä¹‹äº¦ç„¶ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç¼©å°åŒºåŸŸã€‚ä¸ºäº†é¿å…åšå‡ºé”™è¯¯çš„å†³ç­–ï¼Œå¦‚æœç­–ç•¥å˜åŒ–è¿‡å¤§ï¼Œæˆ‘ä»¬å¯ä»¥ç¼©å°ç½®ä¿¡åŸŸã€‚

åœ¨ PPO ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ KL æ•£åº¦æ¥é™åˆ¶æ¯æ¬¡è¿­ä»£ä¸­ç­–ç•¥çš„æ”¹å˜ç¨‹åº¦ã€‚KL æ•£åº¦è¡¡é‡ä¸¤ä¸ªæ•°æ®åˆ†å¸ƒÂ pÂ å’ŒÂ qÂ ä¹‹é—´çš„å·®å¼‚ã€‚

$$
D_{KL}(P\Vert Q)=\mathbb{E}_x\log\frac{P(x)}{Q(x)}
$$

KL æ•£åº¦ç”¨æ¥è¡¡é‡ä¸¤ä¸ªç­–ç•¥ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬ä¸å¸Œæœ›æ–°ç­–ç•¥ä¸ç°æœ‰ç­–ç•¥ä¹‹é—´æœ‰å¤ªå¤§çš„å·®å¼‚ã€‚

![[1_3QNN7laZTbW7guFT-YnJNg.webp]]

é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•é™åˆ¶ç­–ç•¥å˜åŒ–ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šåšå‡ºé”™è¯¯çš„å†³å®šå‘¢ï¼Ÿäº‹å®è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªä¸‹é™å‡½æ•°Â $M$Â ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

$$
M=L(\theta)-C\cdot\overset{\_\_\_\_}{KL}
$$

![[1_FQDiuNJ1WptAN3LnBKYzWw.webp]]

å…¶ä¸­ $L(\theta)$ ç­‰äº

$$
\hat{\mathbb{E}_t}\left[{\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}}\hat{A}_t\right]
$$

ç¬¬äºŒé¡¹æ˜¯ KL æ•£åº¦ã€‚

$L$Â æ˜¯æ–°ç­–ç•¥çš„é¢„æœŸä¼˜åŠ¿å‡½æ•°ï¼ˆé¢„æœŸå¥–åŠ±å‡å»åŸºçº¿å¥–åŠ±ï¼Œä¾‹å¦‚ $V(s)$ ï¼‰ã€‚å®ƒç”±æ—§ç­–ç•¥ï¼ˆæˆ–å½“å‰ç­–ç•¥ï¼‰ä¼°ç®—ï¼Œç„¶åä½¿ç”¨æ–°æ—§ç­–ç•¥ä¹‹é—´çš„æ¦‚ç‡æ¯”é‡æ–°æ ¡å‡†ã€‚==æˆ‘ä»¬ä½¿ç”¨ä¼˜åŠ¿å‡½æ•°ä»£æ›¿é¢„æœŸå¥–åŠ±ï¼Œå› ä¸ºå®ƒå‡å°‘äº†ä¼°è®¡çš„æ–¹å·®== ï¼Œåªè¦åŸºçº¿ä¸ä¾èµ–äºæˆ‘ä»¬çš„ç­–ç•¥å‚æ•°ï¼Œæœ€ä¼˜ç­–ç•¥å°±ä¼šæ˜¯ä¸€æ ·çš„ã€‚

è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°ç ”ç©¶Â $M$Â ä¸­çš„ç¬¬äºŒé¡¹ã€‚ç»è¿‡ TRPO è®ºæ–‡ä¸­ä¸¤é¡µçš„è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥å»ºç«‹ä»¥ä¸‹ä¸‹é™ã€‚

![[1_xqv1aAr6DSXnYFSUMWb6bg.webp]]

$M$Â ä¸­çš„ç¬¬äºŒé¡¹æ˜¯ä¸Šé¢çº¢è‰²ä¸‹åˆ’çº¿æ‰€ç¤ºçš„ KL æ•£åº¦çš„æœ€å¤§å€¼ã€‚ä½†æ˜¯å®ƒå¤ªéš¾æ‰¾åˆ°äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬ç¨å¾®æ”¾å®½äº†è¦æ±‚ï¼Œæ”¹ç”¨ KL æ•£åº¦çš„å¹³å‡å€¼ã€‚è®©æˆ‘ä»¬ç›´è§‚åœ°è§£é‡Šä¸€ä¸‹ã€‚

## ç›´è§‚è§£é‡Š

$L$Â åœ¨å½“å‰ç­–ç•¥ä¸‹å±€éƒ¨è¿‘ä¼¼ä¼˜åŠ¿å‡½æ•°ã€‚ä½†éšç€å®ƒè¿œç¦»æ—§ç­–ç•¥ï¼Œå…¶å‡†ç¡®åº¦ä¼šé™ä½ã€‚è¿™ç§ä¸å‡†ç¡®æ€§æœ‰ä¸€ä¸ªä¸Šé™ï¼Œå³Â $M$Â ä¸­çš„ç¬¬äºŒé¡¹ã€‚è€ƒè™‘åˆ°è¿™ä¸ªè¯¯å·®çš„ä¸Šé™ï¼Œæˆ‘ä»¬å¯ä»¥ä¿è¯åœ¨ç½®ä¿¡åŸŸå†…è®¡ç®—å‡ºçš„æœ€ä¼˜ç­–ç•¥å§‹ç»ˆä¼˜äºæ—§ç­–ç•¥ã€‚å¦‚æœç­–ç•¥åœ¨ç½®ä¿¡åŸŸä¹‹å¤–ï¼Œå³ä½¿è®¡ç®—å€¼å¯èƒ½æ›´å¥½ï¼Œä½†å‡†ç¡®åº¦å¯èƒ½åå·®å¤ªå¤§ï¼Œä¸å¯ä¿¡ã€‚æ‰€ä»¥ä¸èƒ½è¶…å‡ºç½®ä¿¡åŸŸã€‚æˆ‘ä»¬å°†ç›®æ ‡æ€»ç»“å¦‚ä¸‹ï¼š

![[1_LH3dbwj7MEYCICAQMzr-zg.webp]]

ä»æ•°å­¦ä¸Šè®²ï¼Œä¸Šè¿°ä¸¤ä¸ªæ–¹ç¨‹éƒ½å¯ä»¥è§£æä¸ºç›¸åŒçš„æœ€ä¼˜ç­–ç•¥ã€‚ç„¶è€Œï¼ŒÂ $Î´$Â çš„ç†è®ºé˜ˆå€¼éå¸¸å°ï¼Œè¢«è®¤ä¸ºè¿‡äºä¿å®ˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡æ”¾å®½æ¡ä»¶ï¼Œå°†å…¶è®¾ç½®ä¸ºå¯è°ƒè¶…å‚æ•°ã€‚

å¦‚å‰æ‰€è¿°ï¼ŒÂ $M$Â åº”è¯¥æ˜“äºä¼˜åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†å…¶è¿‘ä¼¼ä¸ºä¸€ä¸ªå‡¸å‡½æ•°å½¢å¼çš„äºŒæ¬¡æ–¹ç¨‹ï¼Œå¹¶æ·±å…¥ç ”ç©¶å¦‚ä½•åœ¨é«˜ç»´ç©ºé—´ä¸­å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚

æˆ‘ä»¬ä½¿ç”¨æ³°å‹’çº§æ•°å°†è¿™äº›é¡¹å±•å¼€åˆ°äºŒé˜¶ã€‚ä½†æ˜¯ ğ“› çš„äºŒé˜¶é¡¹æ¯” KL æ•£åº¦é¡¹å°å¾—å¤šï¼Œå› æ­¤å°†è¢«å¿½ç•¥ã€‚

![[1_QKn9GhIMxJmXK_-nAQ8ojA.webp]]

![[1_A386qkCNen7IXjwfFbH2Og.webp]]

å› æ­¤ï¼Œç›®æ ‡å’Œçº¦æŸå¯ä»¥è¿‘ä¼¼ä¸ºï¼š

![[1_Sm49fOBxZBvzgSIo8zm-fA.webp]]

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼š

![[1_3aO-ncPjkdXwfTEsoik9Hg.webp]]

æˆ‘ä»¬å¯ä»¥è§£æåœ°è§£è¿™ä¸ªäºŒæ¬¡æ–¹ç¨‹ã€‚è§£æ˜¯ï¼š

![[3.22.excalidraw]]

## å­˜åœ¨å“ªäº›é—®é¢˜ï¼Ÿ

è¯¥è§£å†³æ–¹æ¡ˆæ¶‰åŠäºŒé˜¶å¯¼æ•°åŠå…¶é€†çš„è®¡ç®—ï¼Œè¿™æ˜¯ä¸€é¡¹éå¸¸æ˜‚è´µçš„æ“ä½œã€‚

$$
\mathbf{H} = \nabla^2 f = 
\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
$$


å› æ­¤ï¼Œæœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

- å¯¹æ¶‰åŠäºŒé˜¶å¯¼æ•°åŠå…¶é€†çš„ä¸€äº›è®¡ç®—è¿›è¡Œè¿‘ä¼¼ï¼Œä»¥é™ä½è®¡ç®—å¤æ‚åº¦
- é€šè¿‡æ·»åŠ è½¯çº¦æŸï¼Œä½¿ä¸€é˜¶å¯¼æ•°è§£åƒæ¢¯åº¦ä¸‹é™ä¸€æ ·æ›´æ¥è¿‘äºŒé˜¶å¯¼æ•°è§£ã€‚

TRPO é‡‡ç”¨ç¬¬ä¸€ç§æ–¹æ³•ã€‚PPO æ›´æ¥è¿‘ç¬¬äºŒç§æ–¹æ³•ã€‚æˆ‘ä»¬ä»ç„¶å¯ä»¥å¿å—å¶å°”å‡ºç°çš„é”™è¯¯ç­–ç•¥å†³ç­–ï¼Œå› æ­¤æˆ‘ä»¬åšæŒä½¿ç”¨åƒéšæœºæ¢¯åº¦ä¸‹é™è¿™æ ·çš„ä¸€é˜¶è§£ã€‚ä½†æˆ‘ä»¬å°†åœ¨ç›®æ ‡å‡½æ•°ä¸­æ·»åŠ ä¸€ä¸ªè½¯çº¦æŸï¼Œè¿™æ ·ä¼˜åŒ–è¿‡ç¨‹å°±èƒ½æ›´å¥½åœ°ç¡®ä¿æˆ‘ä»¬åœ¨ç½®ä¿¡åŸŸå†…è¿›è¡Œä¼˜åŒ–ã€‚å› æ­¤ï¼Œå‡ºç°é”™è¯¯å†³ç­–çš„æ¦‚ç‡ä¼šæ›´å°ã€‚

## å…·æœ‰è‡ªé€‚åº” KL æƒ©ç½šçš„ PPO

åˆ¶å®šç›®æ ‡çš„ä¸€ç§æ–¹æ³•æ˜¯å°†ç›®æ ‡å‡½æ•°ä¸­çš„çº¦æŸæ”¹ä¸ºæƒ©ç½šï¼š

$$
\underset{\theta}{\text{æœ€å¤§åŒ–}}\quad\hat{\mathbb{E}}_t\left[{\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\hat{A}_t}\right]-\beta\hat{\mathbb{E}_t}[KL[\pi_{\theta_{old}}(\cdot|s_t),\pi_\theta(\cdot|s_t)]]
$$

$Î²$Â æ§åˆ¶æƒ©ç½šçš„æƒé‡ã€‚å¦‚æœæ–°ç­–ç•¥ä¸æ—§ç­–ç•¥ä¸åŒï¼Œåˆ™æƒ©ç½šç›®æ ‡ã€‚å€Ÿé‰´ç½®ä¿¡åŸŸçš„æ¦‚å¿µï¼Œæˆ‘ä»¬å¯ä»¥åŠ¨æ€è°ƒæ•´Â $Î²$ ã€‚ä¸‹æ–¹çš„ $d$Â æ˜¯æ–°æ—§ç­–ç•¥ä¹‹é—´çš„ KL æ•£åº¦ã€‚å¦‚æœå®ƒé«˜äºç›®æ ‡å€¼ï¼Œæˆ‘ä»¬å°±ç¼©å°Â $Î²$Â ã€‚åŒæ ·ï¼Œå¦‚æœå®ƒä½äºå¦ä¸€ä¸ªç›®æ ‡å€¼ï¼Œæˆ‘ä»¬å°±æ‰©å¤§ç½®ä¿¡åŸŸã€‚

$$
d=\hat{\mathbb{E}_t}[KL[\pi_{\theta_{old}}(\cdot|s_t),\pi_\theta(\cdot|s_t)]]
$$

ç®—æ³•å¦‚ä¸‹

```pseudo
    \begin{algorithm}
    \caption{1 å¸¦è‡ªé€‚åº”KLæƒ©ç½šçš„PPO}
    \begin{algorithmic}
      \State è¾“å…¥ï¼šåˆå§‹åŒ–ç­–ç•¥å‚æ•° $\theta_0$ ï¼Œåˆå§‹åŒ– KL æƒ©ç½š $\beta_0$ ï¼ŒKLæ•£åº¦çš„ç›®æ ‡ $\delta$
      \For{$k = 0,1,2,\dots$}
      \State ä½¿ç”¨ç­–ç•¥ $\pi_k=\pi(\theta_k)$ é‡‡é›†ä¸€ç»„ç­–ç•¥ $\mathcal{D}_k$
      \State è®¡ç®—ä¼˜åŠ¿ $\hat{A}_t^{\pi_k}$
      \State è®¡ç®—ç­–ç•¥çš„æ›´æ–°ï¼ˆé€šè¿‡æ‰§è¡ŒKæ­¥çš„å¾®æ‰¹æ¬¡SGDï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼‰
      \State
      $
      \theta_{k+1}=\underset{\theta}{\arg\max}\mathcal{L}_{\theta_k}(\theta)-\beta_k\overset{\_}{D}_{KL}(\theta\Vert\theta_k)
      $
      \If{$\overset{\_}{D}_{KL}(\theta_{k+1}\Vert\theta_k)\ge 1.5\delta$}
      \State $\beta_{k+1}=2\beta_k$
      \Elif{$\overset{\_}{D}_{KL}(\theta_{k+1}\Vert\theta_k)\le \delta/1.5$}
      \State $\beta_{k+1}=\beta_k/2$
      \EndIf
      \EndFor
      \end{algorithmic}
    \end{algorithm}
```

è¿™ä½¿å¾— TRPO çš„æ€§èƒ½æ›´æ¥è¿‘æ¢¯åº¦ä¸‹é™æ³•çš„é€Ÿåº¦ã€‚ä½†æˆ‘ä»¬èƒ½åšå¾—æ›´å¥½å—ï¼Ÿ

## å¸¦è£å‰ªç›®æ ‡çš„PPO

å¸¦æœ‰è£å‰ªç›®æ ‡çš„ PPO ç”šè‡³å¯ä»¥åšå¾—æ›´å¥½ã€‚åœ¨å…¶å®ç°ä¸­ï¼Œæˆ‘ä»¬ç»´æŠ¤ä¸¤ä¸ªç­–ç•¥ç½‘ç»œã€‚ç¬¬ä¸€ä¸ªæ˜¯æˆ‘ä»¬æƒ³è¦æ”¹è¿›çš„å½“å‰ç­–ç•¥ã€‚

$$
\pi_\theta(a_t|s_t)
$$

ç¬¬äºŒä¸ªæ˜¯æˆ‘ä»¬ä¸Šæ¬¡é‡‡é›†æ ·æœ¬çš„ç­–ç•¥ã€‚

$$
\pi_{\theta_k}(a_t|s_t)
$$

åˆ©ç”¨é‡è¦æ€§é‡‡æ ·çš„æ€æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä»æ—§ç­–ç•¥ä¸­æ”¶é›†çš„æ ·æœ¬æ¥è¯„ä¼°æ–°ç­–ç•¥ï¼Œä»è€Œæé«˜æ ·æœ¬æ•ˆç‡ã€‚

$$
\underset{\theta}{\text{æœ€å¤§åŒ–}}\quad\hat{\mathbb{E}}_t\left[{\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\hat{A}_t}\right]
$$

ä½†æ˜¯ï¼Œéšç€æˆ‘ä»¬å¯¹ç°æœ‰ç­–ç•¥è¿›è¡Œæ”¹è¿›ï¼Œç°æœ‰ç­–ç•¥ä¸æ—§ç­–ç•¥ä¹‹é—´çš„å·®å¼‚ä¼šè¶Šæ¥è¶Šå¤§ã€‚ä¼°è®¡çš„æ–¹å·®ä¼šå¢åŠ ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå› ä¸ºä¸å‡†ç¡®è€Œåšå‡ºé”™è¯¯çš„å†³ç­–ã€‚å› æ­¤ï¼Œå‡è®¾æ¯è¿›è¡Œ4æ¬¡è¿­ä»£ï¼Œæˆ‘ä»¬å°±å°†ç¬¬äºŒä¸ªç½‘ç»œä¸æ”¹è¿›åçš„ç­–ç•¥å†æ¬¡åŒæ­¥ã€‚

$$
\pi_{\theta_{k+1}}(a_t|s_t)\leftarrow\pi_\theta(a_t|s_t)
$$

é€šè¿‡ä¿®å‰ªç›®æ ‡ï¼Œæˆ‘ä»¬è®¡ç®—æ–°ç­–ç•¥ä¸æ—§ç­–ç•¥ä¹‹é—´çš„æ¯”ç‡ï¼š

$$
r_t(\theta)=\pi_\theta(a_t|s_t)/\pi_{\theta_{k}}(a_t|s_t)
$$

è¿™ä¸ªæ¯”ç‡è¡¡é‡äº†ä¸¤ä¸ªç­–ç•¥ä¹‹é—´çš„å·®å¼‚ç¨‹åº¦ã€‚å¦‚æœæ–°ç­–ç•¥ä¸æ—§ç­–ç•¥ç›¸å·®ç”šè¿œï¼Œæˆ‘ä»¬ä¼šæ„å»ºä¸€ä¸ªæ–°çš„ç›®æ ‡å‡½æ•°æ¥é™åˆ¶ä¼°è®¡çš„ä¼˜åŠ¿å‡½æ•°ã€‚æˆ‘ä»¬çš„æ–°ç›®æ ‡å‡½æ•°å˜ä¸ºï¼š

$$
\mathcal{L}^{CLIP}_{\theta_k}=\underset{\tau\sim\pi_k}{\mathbb{E}}\left[{\sum_{t=0}^T[\min(r_t(\theta)\hat{A}_t^{\pi_k},\text{clip}(r_t(\theta),1-\epsilon,1+\epsilon)\hat{A}_t^{\pi_k})]}\right]
$$

å¦‚æœæ–°ç­–ç•¥ä¸æ—§ç­–ç•¥çš„æ¦‚ç‡æ¯”è¶…å‡º $(1-\epsilon)$ å’Œ $(1+\epsilon)$ çš„èŒƒå›´ï¼Œåˆ™ä¼˜åŠ¿å‡½æ•°å°†è¢«å‰ªè£ã€‚åœ¨ PPO è®ºæ–‡ä¸­çš„å®éªŒä¸­ï¼Œ$\epsilon$ è®¾ç½®ä¸º $0.2$ ã€‚

![[1_MpPiARNoNGCxJE2a8m9itA.webp]]

å®é™…ä¸Šï¼Œå¦‚æœç­–ç•¥å‘ç”Ÿé‡å¤§å˜åŒ–è¶…å‡ºäº†æˆ‘ä»¬çš„èˆ’é€‚åŒºï¼Œé‚£ä¹ˆè¿™å°†é˜»ç¢ç­–ç•¥çš„å®ç°ã€‚

ç®—æ³•å¦‚ä¸‹

```pseudo
    \begin{algorithm}
    \caption{2 å¸¦è£å‰ªç›®æ ‡çš„PPO}
    \begin{algorithmic}
      \State è¾“å…¥ï¼šåˆå§‹åŒ–ç­–ç•¥å‚æ•° $\theta_0$ ï¼Œåˆå§‹åŒ–è£å‰ªé˜ˆå€¼å‚æ•° $\epsilon$
      \For{$k = 0,1,2,\dots$}
      \State ä½¿ç”¨ç­–ç•¥ $\pi_k=\pi(\theta_k)$ é‡‡é›†ä¸€ç»„ç­–ç•¥ $\mathcal{D}_k$
      \State è®¡ç®—ä¼˜åŠ¿ $\hat{A}_t^{\pi_k}$
      \State è®¡ç®—ç­–ç•¥çš„æ›´æ–°ï¼ˆé€šè¿‡æ‰§è¡ŒKæ­¥çš„å¾®æ‰¹æ¬¡SGDï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼‰
      \State
      $
      \theta_{k+1}=\underset{\theta}{\arg\max}\mathcal{L}_{\theta_k}^{CLIP}(\theta)
      $
      \State å…¶ä¸­
      \State
      $\quad\quad
      \mathcal{L}^{CLIP}_{\theta_k}=\underset{\tau\sim\pi_k}{\mathbb{E}}\left[{\sum_{t=0}^T[\min(r_t(\theta)\hat{A}_t^{\pi_k},\text{clip}(r_t(\theta),1-\epsilon,1+\epsilon)\hat{A}_t^{\pi_k})]}\right]
      $
      \EndFor
      \end{algorithmic}
    \end{algorithm}
```

è¿™ä¸ªæ–°æ–¹æ³•å¾ˆç®€å•ï¼Œè€Œä¸”å¯ä»¥åƒ Adam ä¸€æ ·ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥ä¼˜åŒ–ã€‚å…¶å®ï¼Œå¯¹è¿™ä¸ªé—®é¢˜åˆ†æå¾—è¿™ä¹ˆè¯¦ç»†ï¼Œå´å¾—å‡ºè¿™ä¹ˆç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œå®åœ¨æ˜¯æœ‰ç‚¹è™å¤´è›‡å°¾ã€‚

PPO å¢åŠ äº†ä¸€ä¸ªè½¯çº¦æŸï¼Œå¯ä»¥é€šè¿‡ä¸€é˜¶ä¼˜åŒ–å™¨è¿›è¡Œä¼˜åŒ–ã€‚æˆ‘ä»¬å¶å°”å¯èƒ½ä¼šåšå‡ºä¸€äº›é”™è¯¯çš„å†³ç­–ï¼Œä½†å®ƒåœ¨ä¼˜åŒ–é€Ÿåº¦ä¸Šå–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿™ç§å¹³è¡¡èƒ½å¤Ÿä»¥æœ€ç®€å•çš„æ–¹å¼å®ç°æœ€ä½³æ€§èƒ½ã€‚

```ad-note
æ·±åº¦å­¦ä¹ ä¸­çš„ç®€å•è§„åˆ™ã€‚
```

æˆ–è€…è‡³å°‘ç­‰æˆ‘ä»¬å‘æ˜è¶…å¿«çš„ GPU ã€‚è€Œè¿™æ˜¯ä¸å¯èƒ½çš„ã€‚

## PPO ä»£ç å®è·µ

æˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨å€’ç«‹æ‘†ç¯å¢ƒæ¥æµ‹è¯• PPO ç®—æ³•ã€‚å¤§é‡å®ç°è¡¨æ˜ï¼šå¸¦è£å‰ªç›®æ ‡çš„PPOç®—æ³•æ¯”å¸¦KLæƒ©ç½šçš„PPOç®—æ³•è¡¨ç°æ›´å¥½ã€‚æ‰€ä»¥æˆ‘ä»¬å®ç°å¸¦è£å‰ªç›®æ ‡çš„PPOç®—æ³•ã€‚

é¦–å…ˆå®šä¹‰ç­–ç•¥çš„ç½‘ç»œç»“æ„å’Œä»·å€¼ç½‘ç»œ

```python
import gym
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt

class PolicyNet(torch.nn.Module):
	'''ç­–ç•¥ç½‘ç»œ'''
    def __init__(self, state_dim, hidden_dim, action_dim):
        super(PolicyNet, self).__init__()
        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)
        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        return F.softmax(self.fc2(x), dim=1)

class ValueNet(torch.nn.Module):
	'''ä»·å€¼ç½‘ç»œ'''
    def __init__(self, state_dim, hidden_dim):
        super(ValueNet, self).__init__()
        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)
        self.fc2 = torch.nn.Linear(hidden_dim, 1)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        return self.fc2(x)
```

ç„¶åæˆ‘ä»¬æ¥å®ç°å¸¦è£å‰ªç›®æ ‡çš„PPOç®—æ³•

```python
class PPO:
    ''' PPOç®—æ³•,é‡‡ç”¨æˆªæ–­æ–¹å¼ '''
    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,
                 lmbda, epochs, eps, gamma, device):
        # æ¼”å‘˜æ˜¯ç­–ç•¥ç½‘ç»œ
        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)
        # è¯„è®ºå®¶æ˜¯ä»·å€¼ç½‘ç»œ
        self.critic = ValueNet(state_dim, hidden_dim).to(device)
        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),
                                                lr=actor_lr)
        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),
                                                 lr=critic_lr)
        self.gamma = gamma
        self.lmbda = lmbda
        self.epochs = epochs
        self.eps = eps  # PPOä¸­æˆªæ–­èŒƒå›´çš„å‚æ•°
        self.device = device

	# é‡‡å–åŠ¨ä½œ
    def take_action(self, state):
        state = torch.tensor([state], dtype=torch.float).to(self.device)
        probs = self.actor(state)
        action_dist = torch.distributions.Categorical(probs)
        action = action_dist.sample()
        return action.item()

	# æ›´æ–°ç­–ç•¥
    def update(self, transition_dict):
        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)
        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device)
        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)
        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)
        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device)

        td_target = rewards + self.gamma * self.critic(next_states) * (1 - dones)
        td_delta = td_target - self.critic(states)

        advantage = compute_advantage(self.gamma, self.lmbda, td_delta.cpu()).to(self.device)

        old_log_probs = torch.log(self.actor(states).gather(1, actions)).detach()

        for _ in range(self.epochs):
            log_probs = torch.log(self.actor(states).gather(1, actions))
            ratio = torch.exp(log_probs - old_log_probs)
            surr1 = ratio * advantage
            surr2 = torch.clamp(ratio, 1 - self.eps, 1 + self.eps) * advantage
            actor_loss = torch.mean(-torch.min(surr1, surr2))  # PPOæŸå¤±å‡½æ•°
            critic_loss = torch.mean(
                F.mse_loss(self.critic(states), td_target.detach()))
            self.actor_optimizer.zero_grad()
            self.critic_optimizer.zero_grad()
            actor_loss.backward()
            critic_loss.backward()
            self.actor_optimizer.step()
            self.critic_optimizer.step()
```

ç®—æ³•ä¸­è®¡ç®—ä¼˜åŠ¿çš„ä»£ç  `compute_advantage` å¦‚ä¸‹

```python
def compute_advantage(gamma, lmbda, td_delta):
    td_delta = td_delta.detach().numpy()
    advantage_list = []
    advantage = 0.0
    for delta in td_delta[::-1]:
        advantage = gamma * lmbda * advantage + delta
        advantage_list.append(advantage)
    advantage_list.reverse()
    return torch.tensor(advantage_list, dtype=torch.float)
```

æ¥ä¸‹æ¥ï¼Œåœ¨å€’ç«‹æ‘†ç¯å¢ƒä¸­è®­ç»ƒ PPO ç®—æ³•ã€‚

```python
actor_lr = 1e-3
critic_lr = 1e-2
num_episodes = 500
hidden_dim = 128
gamma = 0.98
lmbda = 0.95
epochs = 10
eps = 0.2
device = torch.device("cuda") if torch.cuda.is_available() else torch.device(
    "cpu")

env_name = 'CartPole-v0'
env = gym.make(env_name)
env.seed(0)
torch.manual_seed(0)
state_dim = env.observation_space.shape[0]
action_dim = env.action_space.n
agent = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,
            epochs, eps, gamma, device)

return_list = train_on_policy_agent(env, agent, num_episodes)
```

å…¶ä¸­ `train_on_policy_agent` å¦‚ä¸‹

```python
def train_on_policy_agent(env, agent, num_episodes):
    return_list = []
    for i in range(10):
        with tqdm(total=int(num_episodes/10), desc='Iteration %d' % i) as pbar:
            for i_episode in range(int(num_episodes/10)):
                episode_return = 0
                transition_dict = {'states': [], 'actions': [], 'next_states': [], 'rewards': [], 'dones': []}
                state = env.reset()
                done = False
                while not done:
                    action = agent.take_action(state)
                    next_state, reward, done, _ = env.step(action)
                    transition_dict['states'].append(state)
                    transition_dict['actions'].append(action)
                    transition_dict['next_states'].append(next_state)
                    transition_dict['rewards'].append(reward)
                    transition_dict['dones'].append(done)
                    state = next_state
                    episode_return += reward
                return_list.append(episode_return)
                agent.update(transition_dict)
                if (i_episode+1) % 10 == 0:
                    pbar.set_postfix({'episode': '%d' % (num_episodes/10 * i + i_episode+1), 'return': '%.3f' % np.mean(return_list[-10:])})
                pbar.update(1)
    return return_list
```

å¯è§†åŒ–ä¸€ä¸‹è®­ç»ƒç»“æœ

```python
episodes_list = list(range(len(return_list)))
plt.plot(episodes_list, return_list)
plt.xlabel('Episodes')
plt.ylabel('Returns')
plt.title('CartPole-v0')
plt.show()
```

![[Figure_1.png]]

## æ€»ç»“

PPO æ˜¯ TRPO çš„ä¸€ç§æ”¹è¿›ç®—æ³•ï¼Œå®ƒåœ¨å®ç°ä¸Šç®€åŒ–äº† TRPO ä¸­çš„å¤æ‚è®¡ç®—ï¼Œå¹¶ä¸”å®ƒåœ¨å®éªŒä¸­çš„æ€§èƒ½å¤§å¤šæ•°æƒ…å†µä¸‹ä¼šæ¯” TRPO æ›´å¥½ï¼Œå› æ­¤ç›®å‰å¸¸è¢«ç”¨ä½œä¸€ç§å¸¸ç”¨çš„åŸºå‡†ç®—æ³•ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒTRPO å’Œ PPO éƒ½å±äºåŒç­–ç•¥å­¦ä¹ ç®—æ³•ï¼Œå³ä½¿ä¼˜åŒ–ç›®æ ‡ä¸­åŒ…å«é‡è¦æ€§é‡‡æ ·çš„è¿‡ç¨‹ï¼Œä½†å…¶åªæ˜¯ç”¨åˆ°äº†ä¸Šä¸€è½®ç­–ç•¥çš„æ•°æ®ï¼Œè€Œä¸æ˜¯è¿‡å»æ‰€æœ‰ç­–ç•¥çš„æ•°æ®ã€‚

PPO æ˜¯ TRPO çš„ç¬¬ä¸€ä½œè€… John Schulman ä»åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡åšå£«æ¯•ä¸šååœ¨ OpenAI å…¬å¸ç ”ç©¶å‡ºæ¥çš„ã€‚é€šè¿‡å¯¹ TRPO è®¡ç®—æ–¹å¼çš„æ”¹è¿›ï¼ŒPPO æˆä¸ºäº†æœ€å—å…³æ³¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¹‹ä¸€ï¼Œå¹¶ä¸”å…¶è®ºæ–‡çš„å¼•ç”¨é‡ä¹Ÿè¶…è¶Šäº† TRPOã€‚